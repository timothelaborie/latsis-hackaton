{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing gelectra\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "[-4.737 -4.211  1.678  0.399 -5.08  -2.838  3.709 -2.921 -5.411 -2.713 ... -5.245 -1.826 -3.293 -5.199  2.943  0.994 -5.316 -5.384 -5.465 -0.615]\n",
      "processing mdebertav3\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "[-3.457 -3.743  0.55  -2.819 -4.592 -1.382  3.414  2.274 -4.465  1.606 ... -4.858 -2.455 -4.244 -4.709 -1.445 -0.313 -4.715 -3.898 -4.553 -2.209]\n",
      "processing semantic\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "[-3.034 -6.41   2.634 -2.649 -6.52  -4.691  6.098  1.025 -6.7   -2.069 ... -6.769  0.807 -5.747 -4.898  4.509 -6.056 -6.545 -2.746 -4.732 -0.951]\n",
      "processing xlm_roberta_base\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "[-1.657 -2.62   0.593  2.409 -5.043 -2.095  4.179 -0.085 -5.042 -4.253 ... -5.693 -0.361 -3.874  2.558 -0.201 -1.76  -4.978 -1.013 -4.747 -4.608]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "np.set_printoptions(suppress=True, precision=3, edgeitems=10, linewidth=200)\n",
    "\n",
    "test_x_df = pd.read_csv(\"/kaggle/input/latsis-experiments/mock_test_set.csv\")[\"text\"].tolist()\n",
    "text_y_df = pd.read_csv(\"/kaggle/input/latsis-experiments/mock_test_labels.csv\")[\"label\"].tolist()\n",
    "\n",
    "test_x_df = test_x_df[:2000]\n",
    "text_y_df = text_y_df[:2000]\n",
    "\n",
    "test_y = np.array(text_y_df, dtype=np.float32)\n",
    "test_y = np.round(test_y)\n",
    "\n",
    "def encode_texts(tokenizer, texts):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for text in texts:\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        input_ids.append(encoding['input_ids'])\n",
    "        attention_masks.append(encoding['attention_mask'])\n",
    "    return torch.tensor(input_ids), torch.tensor(attention_masks)\n",
    "\n",
    "\n",
    "stuff = os.listdir(\"/kaggle/working/ensemble/\")\n",
    "for folder in stuff:\n",
    "    if folder.__contains__(\".\"):# or not folder.__contains__(\"swissbert\"):\n",
    "        continue\n",
    "\n",
    "    print(\"processing \" + folder)\n",
    "\n",
    "    model = torch.load(\"/kaggle/working/ensemble/\" + folder + \"/model.pt\").cuda()\n",
    "    tokenizer = torch.load(\"/kaggle/working/ensemble/\" + folder + \"/tokenizer.pt\")\n",
    "    if folder.__contains__(\"swissbert\"):\n",
    "        model.set_default_language(\"de_CH\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_x, test_attention_mask = encode_texts(tokenizer, test_x_df)\n",
    "\n",
    "    BS = 5\n",
    "    predictions = []\n",
    "    for i in range(0, len(test_x), BS):\n",
    "        batch = test_x[i:i+BS].cuda()\n",
    "        batch_attention_mask = test_attention_mask[i:i+BS].cuda()\n",
    "\n",
    "        with torch.no_grad():  # Deactivate autograd engine to reduce memory usage\n",
    "            prediction = model(batch, attention_mask=batch_attention_mask).logits.squeeze(-1)\n",
    "        predictions.append(prediction.cpu().detach())  # Detach before moving to CPU\n",
    "\n",
    "        del batch\n",
    "        del batch_attention_mask\n",
    "        del prediction\n",
    "        torch.cuda.empty_cache()  # Free up memory\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "    \n",
    "    predictions = torch.cat(predictions)\n",
    "    predictions = predictions.detach().numpy()\n",
    "    #print(predictions)\n",
    "\n",
    "    #check f1\n",
    "    predictions2 = np.round(F.sigmoid(torch.tensor(predictions)).numpy())\n",
    "    # print(predictions2)\n",
    "    # print(test_y)\n",
    "    print(\"f1: \" + str(f1_score(test_y, predictions2, average='macro')))\n",
    "\n",
    "    del model\n",
    "    del tokenizer\n",
    "    del test_x\n",
    "    del test_attention_mask\n",
    "    torch.cuda.empty_cache()  # Free up memory\n",
    "    gc.collect()  # Trigger Python garbage collection\n",
    "\n",
    "    np.save(\"/kaggle/working/ensemble/\" + folder + \"/predictions.npy\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "#average predictions\n",
    "all_predictions = []\n",
    "for folder in stuff:\n",
    "    if folder.__contains__(\".\"):\n",
    "        continue\n",
    "    if folder.__contains__(\"swissbert\"):\n",
    "        continue\n",
    "    predictions = np.load(\"/kaggle/working/ensemble/\" + folder + \"/predictions.npy\")\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "all_predictions = np.mean(all_predictions, axis=0)\n",
    "all_predictions = F.sigmoid(torch.from_numpy(all_predictions)).numpy()\n",
    "print(all_predictions.shape)\n",
    "\n",
    "#save to a csv file\n",
    "df = pd.DataFrame(all_predictions, columns=[\"pred\"])\n",
    "df.to_csv(\"/kaggle/working/predictions.csv\", index=False)\n",
    "\n",
    "print(\"f1: \" + str(f1_score(test_y, np.round(all_predictions), average='macro')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
