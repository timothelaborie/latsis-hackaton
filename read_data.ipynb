{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "german_datasets = pd.DataFrame(columns=[\"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "news1 = pd.read_csv(\"data/german/news/RP-Mod.csv\")\n",
    "news1\n",
    "german_datasets = pd.concat([german_datasets, news1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "news2 = pd.read_csv(\"data/german/news/RP-Crowd-1.csv\")\n",
    "news2\n",
    "german_datasets = pd.concat([german_datasets, news1[[\"text\", \"label\"]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "refugee = pd.read_csv(\"data/german/refugee/german hatespeech refugees.csv\")\n",
    "refugee[\"text\"] = refugee[\"Tweet\"]\n",
    "refugee[\"label\"] = (refugee[\"Hatespeech Rating (Expert 2)\"]-1)/5\n",
    "refugee\n",
    "german_datasets = pd.concat([german_datasets, refugee[[\"text\", \"label\"]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.read_csv(\"data/german/foreigners/comments.csv\")\n",
    "annotated_comments_df = pd.read_csv(\"data/german/foreigners/annotated_comments.csv\")\n",
    "\n",
    "# Group by 'comment_id' and calculate the mean valence for each 'comment_id'\n",
    "grouped_df = annotated_comments_df.groupby(\"comment_id\")[\"valence\"].mean().reset_index()\n",
    "\n",
    "# Merge the dataframes on 'comment_id'\n",
    "final_df = pd.merge(comments_df, grouped_df, on=\"comment_id\", how=\"inner\")\n",
    "\n",
    "# Rename columns to 'text' and 'label'\n",
    "final_df = final_df.rename(columns={\"message\": \"text\", \"valence\": \"label\"})\n",
    "\n",
    "# keep only the columns 'text' and 'label'\n",
    "final_df = final_df[[\"text\", \"label\"]]\n",
    "\n",
    "final_df[\"label\"] = final_df[\"label\"]-1\n",
    "\n",
    "german_datasets = pd.concat([german_datasets, final_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasoc = pd.read_csv(\"data/german/hasoc/german_dataset.tsv\", sep=\"\\t\")\n",
    "# hasoc[\"task_1\"] is always either NOT or HOF\n",
    "hasoc[\"label\"] = hasoc[\"task_1\"].map({\"NOT\": 0, \"HOF\": 1})\n",
    "\n",
    "german_datasets = pd.concat([german_datasets, hasoc[[\"text\", \"label\"]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "germeval2018 = pd.read_csv(\"data/german/germeval2018/germeval2018.training.txt\", sep=\"\\t\", header=None)\n",
    "germeval2018.columns = [\"text\", \"label\", \"label2\"]\n",
    "germeval2018[\"label\"] = germeval2018[\"label\"].map({\"OTHER\": 0, \"OFFENSE\": 1})\n",
    "germeval2018[\"origin\"] = \"germeval\"\n",
    "\n",
    "german_datasets = pd.concat([german_datasets, germeval2018[[\"text\", \"label\", \"origin\"]]], ignore_index=True)\n",
    "\n",
    "germeval2018 = pd.read_csv(\"data/german/germeval2018/germeval2018.test.txt\", sep=\"\\t\", header=None)\n",
    "germeval2018.columns = [\"text\", \"label\", \"label2\"]\n",
    "germeval2018[\"label\"] = germeval2018[\"label\"].map({\"OTHER\": 0, \"OFFENSE\": 1})\n",
    "germeval2018[\"origin\"] = \"germeval\"\n",
    "\n",
    "german_datasets = pd.concat([german_datasets, germeval2018[[\"text\", \"label\", \"origin\"]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "germeval2019 = pd.read_csv(\"data/german/germeval2019/Shared-Task-2019_Data_germeval2019.training_subtask1_2.txt\", sep=\"\\t\", header=None)\n",
    "germeval2019.columns = [\"text\", \"label\", \"label2\"]\n",
    "germeval2019[\"label\"] = germeval2019[\"label\"].map({\"OTHER\": 0, \"OFFENSE\": 1})\n",
    "germeval2019[\"origin\"] = \"germeval\"\n",
    "\n",
    "german_datasets = pd.concat([german_datasets, germeval2019[[\"text\", \"label\", \"origin\"]]], ignore_index=True)\n",
    "\n",
    "germeval2019 = pd.read_csv(\"data/german/germeval2019/fz.h-da.de_fileadmin_user_upload_germeval2019GoldLabelsSubtask1_2.txt\", sep=\"\\t\", header=None)\n",
    "germeval2019.columns = [\"text\", \"label\", \"label2\"]\n",
    "germeval2019[\"label\"] = germeval2019[\"label\"].map({\"OTHER\": 0, \"OFFENSE\": 1})\n",
    "germeval2019[\"origin\"] = \"germeval\"\n",
    "\n",
    "german_datasets = pd.concat([german_datasets, germeval2019[[\"text\", \"label\", \"origin\"]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>das alles ist wie Selbstbefriedigung...denn sc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Na Gott sei Dank!!! Wen soll er denn auch besc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naja, er kann sich ja schlecht daneben stellen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oh Gott - jetzt lässt Kellermann auch noch den...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mal gespannt.  als Ausrede warum er niemals be...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57346</th>\n",
       "      <td>Es fand aber nie eine Emanzipierungs-Phase der...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57347</th>\n",
       "      <td>Um es klar zu stellen: Ich will hier kein Whit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57348</th>\n",
       "      <td>Und dann habe ich da noch die McArthur-Briefe ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57349</th>\n",
       "      <td>al sehen wer der Ersatzmann wird. Hier könnte ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57350</th>\n",
       "      <td>@JKasek Oder die Bäume. Bin mal in 'nem Wald s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57351 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label    origin\n",
       "0      das alles ist wie Selbstbefriedigung...denn sc...    1.0       NaN\n",
       "1      Na Gott sei Dank!!! Wen soll er denn auch besc...    1.0       NaN\n",
       "2      Naja, er kann sich ja schlecht daneben stellen...    1.0       NaN\n",
       "3      Oh Gott - jetzt lässt Kellermann auch noch den...    1.0       NaN\n",
       "4      Mal gespannt.  als Ausrede warum er niemals be...    1.0       NaN\n",
       "...                                                  ...    ...       ...\n",
       "57346  Es fand aber nie eine Emanzipierungs-Phase der...    0.0  germeval\n",
       "57347  Um es klar zu stellen: Ich will hier kein Whit...    0.0  germeval\n",
       "57348  Und dann habe ich da noch die McArthur-Briefe ...    0.0  germeval\n",
       "57349  al sehen wer der Ersatzmann wird. Hier könnte ...    0.0  germeval\n",
       "57350  @JKasek Oder die Bäume. Bin mal in 'nem Wald s...    0.0  germeval\n",
       "\n",
       "[57351 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>das alles ist wie Selbstbefriedigung...denn sc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Na Gott sei Dank!!! Wen soll er denn auch besc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naja, er kann sich ja schlecht daneben stellen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oh Gott - jetzt lässt Kellermann auch noch den...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mal gespannt.  als Ausrede warum er niemals be...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34554</th>\n",
       "      <td>Es fand aber nie eine Emanzipierungs-Phase der...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34555</th>\n",
       "      <td>Um es klar zu stellen: Ich will hier kein Whit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34556</th>\n",
       "      <td>Und dann habe ich da noch die McArthur-Briefe ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34557</th>\n",
       "      <td>al sehen wer der Ersatzmann wird. Hier könnte ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34558</th>\n",
       "      <td>@JKasek Oder die Bäume. Bin mal in 'nem Wald s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34558 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label    origin\n",
       "0      das alles ist wie Selbstbefriedigung...denn sc...    1.0       NaN\n",
       "1      Na Gott sei Dank!!! Wen soll er denn auch besc...    1.0       NaN\n",
       "2      Naja, er kann sich ja schlecht daneben stellen...    1.0       NaN\n",
       "3      Oh Gott - jetzt lässt Kellermann auch noch den...    1.0       NaN\n",
       "4      Mal gespannt.  als Ausrede warum er niemals be...    1.0       NaN\n",
       "...                                                  ...    ...       ...\n",
       "34554  Es fand aber nie eine Emanzipierungs-Phase der...    0.0  germeval\n",
       "34555  Um es klar zu stellen: Ich will hier kein Whit...    0.0  germeval\n",
       "34556  Und dann habe ich da noch die McArthur-Briefe ...    0.0  germeval\n",
       "34557  al sehen wer der Ersatzmann wird. Hier könnte ...    0.0  germeval\n",
       "34558  @JKasek Oder die Bäume. Bin mal in 'nem Wald s...    0.0  germeval\n",
       "\n",
       "[34558 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicated text\n",
    "german_datasets = german_datasets.drop_duplicates(subset=[\"text\"])\n",
    "german_datasets = german_datasets.reset_index(drop=True)\n",
    "\n",
    "#remove nan text\n",
    "german_datasets = german_datasets.dropna(subset=[\"text\"])\n",
    "german_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:337: MarkupResemblesLocatorWarning: \".\" looks like a directory name, not markup. You may want to open a file found in this directory and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "def text_cleaning(text):\n",
    "    '''\n",
    "    Cleans text into a basic form for NLP. Operations include the following:-\n",
    "    1. Remove special charecters like &, #, etc\n",
    "    2. Removes extra spaces\n",
    "    3. Removes embedded URL links\n",
    "    4. Removes HTML tags\n",
    "    5. Removes emojis\n",
    "    \n",
    "    text - Text piece to be cleaned.\n",
    "    '''\n",
    "    # print(text)\n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "    only_text = soup.get_text()\n",
    "    text = only_text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "\n",
    "    return text\n",
    "\n",
    "german_datasets[\"text\"] = german_datasets[\"text\"].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "germeval = german_datasets[german_datasets[\"origin\"] == \"germeval\"]\n",
    "pretrain = german_datasets[german_datasets[\"origin\"] != \"germeval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19134</th>\n",
       "      <td>@corinnamilborn Liebe Corinna, wir würden dich...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19135</th>\n",
       "      <td>@Martin28a Sie haben ja auch Recht. Unser Twee...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19136</th>\n",
       "      <td>@ahrens_theo fröhlicher gruß aus der schönsten...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19137</th>\n",
       "      <td>@dushanwegner Amis hätten alles und jeden gewä...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19138</th>\n",
       "      <td>@spdde kein verläßlicher Verhandlungspartner. ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34554</th>\n",
       "      <td>Es fand aber nie eine Emanzipierungs-Phase der...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34555</th>\n",
       "      <td>Um es klar zu stellen: Ich will hier kein Whit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34556</th>\n",
       "      <td>Und dann habe ich da noch die McArthur-Briefe ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34557</th>\n",
       "      <td>al sehen wer der Ersatzmann wird. Hier könnte ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34558</th>\n",
       "      <td>@JKasek Oder die Bäume. Bin mal in 'nem Wald s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15425 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label    origin\n",
       "19134  @corinnamilborn Liebe Corinna, wir würden dich...    0.0  germeval\n",
       "19135  @Martin28a Sie haben ja auch Recht. Unser Twee...    0.0  germeval\n",
       "19136  @ahrens_theo fröhlicher gruß aus der schönsten...    0.0  germeval\n",
       "19137  @dushanwegner Amis hätten alles und jeden gewä...    0.0  germeval\n",
       "19138  @spdde kein verläßlicher Verhandlungspartner. ...    1.0  germeval\n",
       "...                                                  ...    ...       ...\n",
       "34554  Es fand aber nie eine Emanzipierungs-Phase der...    0.0  germeval\n",
       "34555  Um es klar zu stellen: Ich will hier kein Whit...    0.0  germeval\n",
       "34556  Und dann habe ich da noch die McArthur-Briefe ...    0.0  germeval\n",
       "34557  al sehen wer der Ersatzmann wird. Hier könnte ...    0.0  germeval\n",
       "34558  @JKasek Oder die Bäume. Bin mal in 'nem Wald s...    0.0  germeval\n",
       "\n",
       "[15425 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "germeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>das alles ist wie Selbstbefriedigung...denn sc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Na Gott sei Dank!!! Wen soll er denn auch besc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naja, er kann sich ja schlecht daneben stellen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oh Gott - jetzt lässt Kellermann auch noch den...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mal gespannt. als Ausrede warum er niemals bei...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19129</th>\n",
       "      <td>akquirieren Männer,die sich um die Kinder kümm...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19130</th>\n",
       "      <td>Ja,schon seit Jahren! Ich muß dran denken,das ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19131</th>\n",
       "      <td>@Kurkamp @wendt_joachim @Schroeder_Live @lamni...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19132</th>\n",
       "      <td>EU Wahlen! AfD für Kindererziehungszeiten für ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19133</th>\n",
       "      <td>Es ist schon merkwürdig,da soll ein Wettstreit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19133 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label origin\n",
       "0      das alles ist wie Selbstbefriedigung...denn sc...    1.0    NaN\n",
       "1      Na Gott sei Dank!!! Wen soll er denn auch besc...    1.0    NaN\n",
       "2      Naja, er kann sich ja schlecht daneben stellen...    1.0    NaN\n",
       "3      Oh Gott - jetzt lässt Kellermann auch noch den...    1.0    NaN\n",
       "4      Mal gespannt. als Ausrede warum er niemals bei...    1.0    NaN\n",
       "...                                                  ...    ...    ...\n",
       "19129  akquirieren Männer,die sich um die Kinder kümm...    0.0    NaN\n",
       "19130  Ja,schon seit Jahren! Ich muß dran denken,das ...    0.0    NaN\n",
       "19131  @Kurkamp @wendt_joachim @Schroeder_Live @lamni...    0.0    NaN\n",
       "19132  EU Wahlen! AfD für Kindererziehungszeiten für ...    0.0    NaN\n",
       "19133  Es ist schon merkwürdig,da soll ein Wettstreit...    0.0    NaN\n",
       "\n",
       "[19133 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    10334\n",
      "1.0     5091\n",
      "Name: label, dtype: int64\n",
      "0.000000    10932\n",
      "1.000000     7837\n",
      "0.200000      107\n",
      "0.500000       80\n",
      "0.600000       75\n",
      "0.400000       68\n",
      "0.800000       30\n",
      "0.750000        2\n",
      "0.333333        1\n",
      "0.666667        1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(germeval[\"label\"].value_counts())\n",
    "print(pretrain[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the files to parquet\n",
    "germeval.to_parquet(\"germeval.parquet\")\n",
    "pretrain.to_parquet(\"pretrain.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
