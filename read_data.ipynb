{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "german_datasets = pd.DataFrame(columns=[\"text\", \"label\"])\n",
    "german_datasets = german_datasets.astype({\"text\": str, \"label\": np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "news1 = pd.read_csv(\"data/german/news/RP-Mod.csv\")\n",
    "news1\n",
    "german_datasets = pd.concat([german_datasets, news1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "news2 = pd.read_csv(\"data/german/news/RP-Crowd-1.csv\")\n",
    "news2\n",
    "german_datasets = pd.concat([german_datasets, news1[[\"text\", \"label\"]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "refugee = pd.read_csv(\"data/german/refugee/german hatespeech refugees.csv\")\n",
    "refugee[\"text\"] = refugee[\"Tweet\"]\n",
    "refugee[\"label\"] = (refugee[\"Hatespeech Rating (Expert 2)\"]-1)/5\n",
    "refugee\n",
    "german_datasets = pd.concat([german_datasets, refugee[[\"text\", \"label\"]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.read_csv(\"data/german/foreigners/comments.csv\")\n",
    "annotated_comments_df = pd.read_csv(\"data/german/foreigners/annotated_comments.csv\")\n",
    "\n",
    "# Group by 'comment_id' and calculate the mean valence for each 'comment_id'\n",
    "grouped_df = annotated_comments_df.groupby(\"comment_id\")[\"valence\"].mean().reset_index()\n",
    "\n",
    "# Merge the dataframes on 'comment_id'\n",
    "final_df = pd.merge(comments_df, grouped_df, on=\"comment_id\", how=\"inner\")\n",
    "\n",
    "# Rename columns to 'text' and 'label'\n",
    "final_df = final_df.rename(columns={\"message\": \"text\", \"valence\": \"label\"})\n",
    "\n",
    "# keep only the columns 'text' and 'label'\n",
    "final_df = final_df[[\"text\", \"label\"]]\n",
    "\n",
    "final_df[\"label\"] = final_df[\"label\"]-1\n",
    "\n",
    "german_datasets = pd.concat([german_datasets, final_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasoc = pd.read_csv(\"data/german/hasoc/german_dataset.tsv\", sep=\"\\t\")\n",
    "# hasoc[\"task_1\"] is always either NOT or HOF\n",
    "hasoc[\"label\"] = hasoc[\"task_1\"].map({\"NOT\": 0, \"HOF\": 1})\n",
    "\n",
    "german_datasets = pd.concat([german_datasets, hasoc[[\"text\", \"label\"]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "germeval2018 = pd.read_csv(\"data/german/germeval2018/germeval2018.training.txt\", sep=\"\\t\", header=None)\n",
    "germeval2018.columns = [\"text\", \"label\", \"label2\"]\n",
    "germeval2018[\"label\"] = germeval2018[\"label\"].map({\"OTHER\": 0, \"OFFENSE\": 1})\n",
    "germeval2018[\"origin\"] = \"germeval\"\n",
    "\n",
    "german_datasets = pd.concat([german_datasets, germeval2018[[\"text\", \"label\", \"origin\"]]], ignore_index=True)\n",
    "\n",
    "germeval2018 = pd.read_csv(\"data/german/germeval2018/germeval2018.test.txt\", sep=\"\\t\", header=None)\n",
    "germeval2018.columns = [\"text\", \"label\", \"label2\"]\n",
    "germeval2018[\"label\"] = germeval2018[\"label\"].map({\"OTHER\": 0, \"OFFENSE\": 1})\n",
    "germeval2018[\"origin\"] = \"germeval\"\n",
    "\n",
    "german_datasets = pd.concat([german_datasets, germeval2018[[\"text\", \"label\", \"origin\"]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "germeval2019 = pd.read_csv(\"data/german/germeval2019/Shared-Task-2019_Data_germeval2019.training_subtask1_2.txt\", sep=\"\\t\", header=None)\n",
    "germeval2019.columns = [\"text\", \"label\", \"label2\"]\n",
    "germeval2019[\"label\"] = germeval2019[\"label\"].map({\"OTHER\": 0, \"OFFENSE\": 1})\n",
    "germeval2019[\"origin\"] = \"germeval\"\n",
    "\n",
    "german_datasets = pd.concat([german_datasets, germeval2019[[\"text\", \"label\", \"origin\"]]], ignore_index=True)\n",
    "\n",
    "germeval2019 = pd.read_csv(\"data/german/germeval2019/fz.h-da.de_fileadmin_user_upload_germeval2019GoldLabelsSubtask1_2.txt\", sep=\"\\t\", header=None)\n",
    "germeval2019.columns = [\"text\", \"label\", \"label2\"]\n",
    "germeval2019[\"label\"] = germeval2019[\"label\"].map({\"OTHER\": 0, \"OFFENSE\": 1})\n",
    "germeval2019[\"origin\"] = \"germeval\"\n",
    "\n",
    "german_datasets = pd.concat([german_datasets, germeval2019[[\"text\", \"label\", \"origin\"]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>das alles ist wie Selbstbefriedigung...denn sc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Na Gott sei Dank!!! Wen soll er denn auch besc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naja, er kann sich ja schlecht daneben stellen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oh Gott - jetzt lässt Kellermann auch noch den...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mal gespannt.  als Ausrede warum er niemals be...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57346</th>\n",
       "      <td>Es fand aber nie eine Emanzipierungs-Phase der...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57347</th>\n",
       "      <td>Um es klar zu stellen: Ich will hier kein Whit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57348</th>\n",
       "      <td>Und dann habe ich da noch die McArthur-Briefe ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57349</th>\n",
       "      <td>al sehen wer der Ersatzmann wird. Hier könnte ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57350</th>\n",
       "      <td>@JKasek Oder die Bäume. Bin mal in 'nem Wald s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57351 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label    origin\n",
       "0      das alles ist wie Selbstbefriedigung...denn sc...    1.0       NaN\n",
       "1      Na Gott sei Dank!!! Wen soll er denn auch besc...    1.0       NaN\n",
       "2      Naja, er kann sich ja schlecht daneben stellen...    1.0       NaN\n",
       "3      Oh Gott - jetzt lässt Kellermann auch noch den...    1.0       NaN\n",
       "4      Mal gespannt.  als Ausrede warum er niemals be...    1.0       NaN\n",
       "...                                                  ...    ...       ...\n",
       "57346  Es fand aber nie eine Emanzipierungs-Phase der...    0.0  germeval\n",
       "57347  Um es klar zu stellen: Ich will hier kein Whit...    0.0  germeval\n",
       "57348  Und dann habe ich da noch die McArthur-Briefe ...    0.0  germeval\n",
       "57349  al sehen wer der Ersatzmann wird. Hier könnte ...    0.0  germeval\n",
       "57350  @JKasek Oder die Bäume. Bin mal in 'nem Wald s...    0.0  germeval\n",
       "\n",
       "[57351 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>das alles ist wie Selbstbefriedigung...denn sc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Na Gott sei Dank!!! Wen soll er denn auch besc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naja, er kann sich ja schlecht daneben stellen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oh Gott - jetzt lässt Kellermann auch noch den...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mal gespannt.  als Ausrede warum er niemals be...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34554</th>\n",
       "      <td>Es fand aber nie eine Emanzipierungs-Phase der...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34555</th>\n",
       "      <td>Um es klar zu stellen: Ich will hier kein Whit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34556</th>\n",
       "      <td>Und dann habe ich da noch die McArthur-Briefe ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34557</th>\n",
       "      <td>al sehen wer der Ersatzmann wird. Hier könnte ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34558</th>\n",
       "      <td>@JKasek Oder die Bäume. Bin mal in 'nem Wald s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34558 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label    origin\n",
       "0      das alles ist wie Selbstbefriedigung...denn sc...    1.0       NaN\n",
       "1      Na Gott sei Dank!!! Wen soll er denn auch besc...    1.0       NaN\n",
       "2      Naja, er kann sich ja schlecht daneben stellen...    1.0       NaN\n",
       "3      Oh Gott - jetzt lässt Kellermann auch noch den...    1.0       NaN\n",
       "4      Mal gespannt.  als Ausrede warum er niemals be...    1.0       NaN\n",
       "...                                                  ...    ...       ...\n",
       "34554  Es fand aber nie eine Emanzipierungs-Phase der...    0.0  germeval\n",
       "34555  Um es klar zu stellen: Ich will hier kein Whit...    0.0  germeval\n",
       "34556  Und dann habe ich da noch die McArthur-Briefe ...    0.0  germeval\n",
       "34557  al sehen wer der Ersatzmann wird. Hier könnte ...    0.0  germeval\n",
       "34558  @JKasek Oder die Bäume. Bin mal in 'nem Wald s...    0.0  germeval\n",
       "\n",
       "[34558 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicated text\n",
    "german_datasets = german_datasets.drop_duplicates(subset=[\"text\"])\n",
    "german_datasets = german_datasets.reset_index(drop=True)\n",
    "\n",
    "#remove nan text\n",
    "german_datasets = german_datasets.dropna(subset=[\"text\"])\n",
    "german_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:337: MarkupResemblesLocatorWarning: \".\" looks like a directory name, not markup. You may want to open a file found in this directory and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "def text_cleaning(text):\n",
    "    '''\n",
    "    Cleans text into a basic form for NLP. Operations include the following:-\n",
    "    1. Remove special charecters like &, #, etc\n",
    "    2. Removes extra spaces\n",
    "    3. Removes embedded URL links\n",
    "    4. Removes HTML tags\n",
    "    5. Removes emojis\n",
    "    \n",
    "    text - Text piece to be cleaned.\n",
    "    '''\n",
    "    # print(text)\n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "    only_text = soup.get_text()\n",
    "    text = only_text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "\n",
    "    return text\n",
    "\n",
    "german_datasets[\"text\"] = german_datasets[\"text\"].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "germeval = german_datasets[german_datasets[\"origin\"] == \"germeval\"]\n",
    "pretrain = german_datasets[german_datasets[\"origin\"] != \"germeval\"]\n",
    "\n",
    "#shuffle the data\n",
    "germeval = germeval.sample(frac=1).reset_index(drop=True)\n",
    "pretrain = pretrain.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mittlerweile haben unsere Medien das Niveau de...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@burghard_r Stegner kämpft für seine politisch...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morgen organisiert Antifa en détail - Aachen d...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Tatort Wenn man diesen Tweet mit dem Hashtag ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@AhmadMansour__ Uff, der Tokenismus in Person ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15420</th>\n",
       "      <td>@PamelaCostaric1 Der hat den Arsch voll auf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15421</th>\n",
       "      <td>@Volksverpetzer Da hat #Broder übersehen, dass...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15422</th>\n",
       "      <td>@Tom174_ @mountainman1977 @allesevolution *Auf...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15423</th>\n",
       "      <td>Wenn Merkel wieder gewählt wird dann wird Deut...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15424</th>\n",
       "      <td>@vt27kolt11 Und melde Dich mal bei Deinem Land...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>germeval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15425 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label    origin\n",
       "0      Mittlerweile haben unsere Medien das Niveau de...    1.0  germeval\n",
       "1      @burghard_r Stegner kämpft für seine politisch...    0.0  germeval\n",
       "2      Morgen organisiert Antifa en détail - Aachen d...    0.0  germeval\n",
       "3      @Tatort Wenn man diesen Tweet mit dem Hashtag ...    0.0  germeval\n",
       "4      @AhmadMansour__ Uff, der Tokenismus in Person ...    0.0  germeval\n",
       "...                                                  ...    ...       ...\n",
       "15420        @PamelaCostaric1 Der hat den Arsch voll auf    0.0  germeval\n",
       "15421  @Volksverpetzer Da hat #Broder übersehen, dass...    1.0  germeval\n",
       "15422  @Tom174_ @mountainman1977 @allesevolution *Auf...    0.0  germeval\n",
       "15423  Wenn Merkel wieder gewählt wird dann wird Deut...    1.0  germeval\n",
       "15424  @vt27kolt11 Und melde Dich mal bei Deinem Land...    0.0  germeval\n",
       "\n",
       "[15425 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "germeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wenn mehr nicht kommt von einem BMW-Betriebsra...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unter dem Hashtag #TurksAreComingForIceland ka...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Die Schlepperkönigin startet einen Entlastungs...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Die meisten Berliner/Brandenburger Polizisten ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ganz im Allgemeinen muss mit der AfD mehr gesp...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19128</th>\n",
       "      <td>Einer der besten Kommentare, die ich seit lang...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19129</th>\n",
       "      <td>\"„Vergesst nicht, Michael Cohen ist bereits we...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19130</th>\n",
       "      <td>Muuuurikaaaa ^^ da fällt mir nur ein, du bist ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19131</th>\n",
       "      <td>Ja und in den kommenden Jahren wird man die We...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19132</th>\n",
       "      <td>Nach allgemeiner Verblödungs-Vernichtungs- und...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19133 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label origin\n",
       "0      wenn mehr nicht kommt von einem BMW-Betriebsra...    0.0    NaN\n",
       "1      Unter dem Hashtag #TurksAreComingForIceland ka...    1.0    NaN\n",
       "2      Die Schlepperkönigin startet einen Entlastungs...    1.0    NaN\n",
       "3      Die meisten Berliner/Brandenburger Polizisten ...    0.0    NaN\n",
       "4      Ganz im Allgemeinen muss mit der AfD mehr gesp...    0.0    NaN\n",
       "...                                                  ...    ...    ...\n",
       "19128  Einer der besten Kommentare, die ich seit lang...    0.0    NaN\n",
       "19129  \"„Vergesst nicht, Michael Cohen ist bereits we...    1.0    NaN\n",
       "19130  Muuuurikaaaa ^^ da fällt mir nur ein, du bist ...    0.0    NaN\n",
       "19131  Ja und in den kommenden Jahren wird man die We...    1.0    NaN\n",
       "19132  Nach allgemeiner Verblödungs-Vernichtungs- und...    0.0    NaN\n",
       "\n",
       "[19133 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    10334\n",
      "1.0     5091\n",
      "Name: label, dtype: int64\n",
      "0.000000    10932\n",
      "1.000000     7837\n",
      "0.200000      107\n",
      "0.500000       80\n",
      "0.600000       75\n",
      "0.400000       68\n",
      "0.800000       30\n",
      "0.750000        2\n",
      "0.333333        1\n",
      "0.666667        1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(germeval[\"label\"].value_counts())\n",
    "print(pretrain[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(germeval, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the files to parquet\n",
    "train.to_parquet(\"train.parquet\")\n",
    "test.to_parquet(\"test.parquet\")\n",
    "pretrain.to_parquet(\"pretrain.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
